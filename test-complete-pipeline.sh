#!/bin/bash
# test-complete-pipeline.sh
# Pipeline complet: Fragmentation â†’ Allocation â†’ Distribution

set -e  # Exit on error

DATASET_NAME="watdiv100k"
INPUT_FILE="/home/boumi/Documents/PQDAG GUI/storage/rawdata/${DATASET_NAME}.nt"
NUM_MACHINES=10
API_URL="http://localhost:8080"

echo "========================================="
echo "PQDAG COMPLETE PIPELINE TEST"
echo "========================================="
echo "Dataset: ${DATASET_NAME}"
echo "Machines: ${NUM_MACHINES}"
echo "========================================="
echo ""

# VÃ©rifier que le fichier source existe
if [ ! -f "$INPUT_FILE" ]; then
    echo "âŒ ERROR: Input file not found: $INPUT_FILE"
    exit 1
fi

# VÃ©rifier que l'API est accessible
echo "ğŸ” Checking API health..."
if ! curl -sf "${API_URL}/api/health" > /dev/null; then
    echo "âŒ ERROR: API is not running on ${API_URL}"
    echo "   Start the API with: cd backend/api && mvn spring-boot:run"
    exit 1
fi
echo "âœ… API is healthy"
echo ""

# Ã‰TAPE 1: Fragmentation
echo "========================================="
echo "Ã‰TAPE 1/5: FRAGMENTATION"
echo "========================================="
echo "Processing: $INPUT_FILE"
echo ""

FRAG_RESPONSE=$(curl -sf -X POST "${API_URL}/api/fragmentation/start" \
    -H "Content-Type: application/json" \
    -d "{\"inputFilePath\": \"$INPUT_FILE\", \"inputFormat\": \"NT\"}")

FRAG_STATUS=$(echo "$FRAG_RESPONSE" | jq -r '.status')
if [ "$FRAG_STATUS" != "success" ]; then
    echo "âŒ Fragmentation failed:"
    echo "$FRAG_RESPONSE" | jq .
    exit 1
fi

TOTAL_TRIPLES=$(echo "$FRAG_RESPONSE" | jq -r '.statistics.totalTriples')
NUM_FRAGMENTS=$(echo "$FRAG_RESPONSE" | jq -r '.statistics.totalFragments')
FRAG_TIME=$(echo "$FRAG_RESPONSE" | jq -r '.statistics.executionTime')

echo "âœ… Fragmentation completed:"
echo "   - Total triples: $TOTAL_TRIPLES"
echo "   - Fragments created: $NUM_FRAGMENTS"
echo "   - Execution time: ${FRAG_TIME}s"
echo ""

# Ã‰TAPE 2: Allocation (Stats + Graph + METIS)
echo "========================================="
echo "Ã‰TAPE 2/5: ALLOCATION"
echo "========================================="
echo "Running: stat_MPI.py â†’ generate_fragments_graph.py â†’ weighted_metis.py"
echo ""

ALLOC_RESPONSE=$(curl -sf -X POST "${API_URL}/api/allocation/start" \
    -H "Content-Type: application/json" \
    -d "{\"datasetName\": \"$DATASET_NAME\", \"numMachines\": $NUM_MACHINES, \"cleanAfter\": true}")

ALLOC_STATUS=$(echo "$ALLOC_RESPONSE" | jq -r '.status')
if [ "$ALLOC_STATUS" != "success" ]; then
    echo "âŒ Allocation failed:"
    echo "$ALLOC_RESPONSE" | jq .
    exit 1
fi

TOTAL_FRAGMENTS=$(echo "$ALLOC_RESPONSE" | jq -r '.statistics.totalFragments')
TOTAL_EDGES=$(echo "$ALLOC_RESPONSE" | jq -r '.statistics.totalEdges')
ALLOC_TIME=$(echo "$ALLOC_RESPONSE" | jq -r '.statistics.executionTime')
AFFECTATION_FILE=$(echo "$ALLOC_RESPONSE" | jq -r '.affectationFile')

echo "âœ… Allocation completed:"
echo "   - Total fragments: $TOTAL_FRAGMENTS"
echo "   - Graph edges: $TOTAL_EDGES"
echo "   - Execution time: ${ALLOC_TIME}s"
echo "   - Affectation file: $AFFECTATION_FILE"
echo ""

# Afficher la distribution
echo "ğŸ“Š Distribution per machine:"
echo "$ALLOC_RESPONSE" | jq -r '.distribution[] | "   Machine \(.machineId): \(.fragmentCount) fragments (\(.workerIp))"'
echo ""

# Ã‰TAPE 3: Distribution vers le cluster
echo "========================================="
echo "Ã‰TAPE 3/5: DISTRIBUTION TO CLUSTER"
echo "========================================="
echo "Distributing fragments to workers..."
echo ""

DIST_RESPONSE=$(curl -sf -X POST "${API_URL}/api/allocation/distribute" \
    -H "Content-Type: application/json" \
    -d "{\"datasetName\": \"$DATASET_NAME\"}")

DIST_STATUS=$(echo "$DIST_RESPONSE" | jq -r '.status')
if [ "$DIST_STATUS" != "success" ]; then
    echo "âŒ Distribution failed:"
    echo "$DIST_RESPONSE" | jq .
    exit 1
fi

echo "âœ… Distribution completed successfully"
echo ""

# Ã‰TAPE 4: VÃ©rification sur les workers
echo "========================================="
echo "Ã‰TAPE 4/5: VERIFICATION"
echo "========================================="
echo "Checking fragments on workers..."
echo ""

STORAGE_PATH="/home/ubuntu/mounted_vol/pqdag_data/${DATASET_NAME}"

# VÃ©rifier worker 1 et worker 5
for WORKER_ID in 1 5; do
    WORKER_ALIAS="pqdag-worker-${WORKER_ID}"
    echo "Checking ${WORKER_ALIAS}..."
    
    FRAGMENT_COUNT=$(ssh "$WORKER_ALIAS" "ls -1 ${STORAGE_PATH}/*.data 2>/dev/null | wc -l" 2>/dev/null || echo "0")
    
    if [ "$FRAGMENT_COUNT" -gt 0 ]; then
        echo "âœ… Worker ${WORKER_ID}: $FRAGMENT_COUNT fragments"
    else
        echo "âš ï¸  Worker ${WORKER_ID}: No fragments found (SSH might be needed)"
    fi
done
echo ""

# Ã‰TAPE 5: RÃ©sumÃ© final
echo "========================================="
echo "Ã‰TAPE 5/5: SUMMARY"
echo "========================================="
echo ""
echo "ğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!"
echo ""
echo "ğŸ“Š Summary:"
echo "   â”œâ”€ Fragmentation:"
echo "   â”‚  â”œâ”€ Input triples: $TOTAL_TRIPLES"
echo "   â”‚  â”œâ”€ Fragments created: $NUM_FRAGMENTS"
echo "   â”‚  â””â”€ Time: ${FRAG_TIME}s"
echo "   â”‚"
echo "   â”œâ”€ Allocation:"
echo "   â”‚  â”œâ”€ Fragments analyzed: $TOTAL_FRAGMENTS"
echo "   â”‚  â”œâ”€ Graph edges: $TOTAL_EDGES"
echo "   â”‚  â”œâ”€ Machines: $NUM_MACHINES"
echo "   â”‚  â””â”€ Time: ${ALLOC_TIME}s"
echo "   â”‚"
echo "   â””â”€ Distribution:"
echo "      â”œâ”€ Target: Cluster (10 workers)"
echo "      â””â”€ Status: âœ… Complete"
echo ""
echo "ğŸ“ Generated files:"
echo "   â”œâ”€ Fragments: storage/outputdata/*.{data,dic,schema}"
echo "   â”œâ”€ Statistics: storage/allocation_results/db.stat"
echo "   â”œâ”€ Graph: storage/allocation_results/fragments_graph.quad"
echo "   â””â”€ Allocation: $AFFECTATION_FILE"
echo ""
echo "ğŸŒ View results in GUI: http://localhost:4200"
echo ""
echo "========================================="
